{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc04aa5-3d76-4cce-898f-e59fbe4ec64c",
   "metadata": {},
   "source": [
    "# Train a CNN for Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5aa9b10-99f8-438b-b1c6-4918323314dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9912422/9912422 [00:00<00:00, 26344387.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28881/28881 [00:00<00:00, 1652353.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1648877/1648877 [00:00<00:00, 6110410.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [00:00<00:00, 1916745.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Training Simple Neural Network...\n",
      "Epoch 1, Loss: 0.40448390214300867\n",
      "Epoch 2, Loss: 0.19974939586288892\n",
      "Epoch 3, Loss: 0.14145979561856878\n",
      "Epoch 4, Loss: 0.11732239898806537\n",
      "Epoch 5, Loss: 0.09789502675652996\n",
      "Training Convolutional Neural Network...\n",
      "Epoch 1, Loss: 0.19106504687024697\n",
      "Epoch 2, Loss: 0.05199949782570578\n",
      "Epoch 3, Loss: 0.035507859311812225\n",
      "Epoch 4, Loss: 0.02790432198934117\n",
      "Epoch 5, Loss: 0.02117122623074151\n",
      "Evaluating Simple Neural Network...\n",
      "Accuracy: 96.48%\n",
      "Evaluating Convolutional Neural Network...\n",
      "Accuracy: 98.79%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define a simple Fully Connected Neural Network (Normal NN)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)      # Fully connected layer 1\n",
    "        self.relu = nn.ReLU()                 # Activation function\n",
    "        self.fc2 = nn.Linear(128, 64)         # Fully connected layer 2\n",
    "        self.fc3 = nn.Linear(64, 10)          # Output layer (10 classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)                  # Flatten the 2D image into a 1D vector\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define a Convolutional Neural Network (CNN)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize models, loss function, and optimizer\n",
    "simple_nn = SimpleNN()\n",
    "cnn = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_nn = optim.Adam(simple_nn.parameters(), lr=0.001)\n",
    "optimizer_cnn = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(model, optimizer, train_loader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "# Train both models\n",
    "print(\"Training Simple Neural Network...\")\n",
    "train_model(simple_nn, optimizer_nn, train_loader)\n",
    "\n",
    "print(\"Training Convolutional Neural Network...\")\n",
    "train_model(cnn, optimizer_cnn, train_loader)\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# Evaluate both models\n",
    "print(\"Evaluating Simple Neural Network...\")\n",
    "evaluate_model(simple_nn, test_loader)\n",
    "\n",
    "print(\"Evaluating Convolutional Neural Network...\")\n",
    "evaluate_model(cnn, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b4397-3c53-4553-b189-649926728b85",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f065a0e-c338-4686-8817-a4d647815fe0",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)\n",
    "### Architecture & Layers\n",
    "A **CNN** uses specialized layers to process images:  \n",
    "* **Convolutional Layer:** Detects patterns like edges, corners, and textures.\n",
    "* **Activation Function (ReLU):** Adds non-linearity to help learn complex patterns.\n",
    "* **Pooling Layer (Max Pooling/Average Pooling):** Reduces dimensions while preserving important features.\n",
    "* **Fully Connected Layer (Dense Layer):** Final layer to make classification decisions.\n",
    "\n",
    "### 1ï¸âƒ£ Convolutional Layer (nn.Conv2d)\n",
    "ðŸ“Œ **What it Does?**\n",
    "* Purpose: Detects features (edges, textures) in an image using small filters (kernels).\n",
    "* A filter (kernel) slides over the input image to detect patterns like edges, shapes, and textures.\n",
    "* Each filter learns different features (e.g., one detects horizontal edges, another detects curves, etc.).\n",
    "* How It Works: A 3x3 or 5x5 filter slides over the image, performing element-wise multiplication and summing up the values.\n",
    "* The output is a feature map, highlighting key patterns.\n",
    "ðŸ”¹ **Code in CNN Model**\n",
    "```python\n",
    "self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "```\n",
    "* 1: Input channels (grayscale image has 1 channel).\n",
    "* 16: Number of filters (kernels), meaning 16 different feature detectors.\n",
    "* kernel_size=3: A 3Ã—3 filter slides over the image.\n",
    "* padding=1: Maintains the image size after convolution.\n",
    "ðŸ–¼ **Visual Example**\n",
    "* ðŸ”¹ Original Image (28Ã—28)\n",
    "* ðŸ”¹ After Conv Layer â†’ 16 Feature Maps (28Ã—28 each)\n",
    "\n",
    "âœ… Effect: Extracts low-level features (edges, lines).\n",
    "\n",
    "### 2ï¸âƒ£ ReLU Activation Function (nn.ReLU)\n",
    "ðŸ“Œ **What it Does?**\n",
    "* Introduces non-linearity by replacing negative values with zero.\n",
    "* Helps the CNN learn complex patterns rather than just linear features.\n",
    "ðŸ”¹ **Code in CNN Model**\n",
    "```python\n",
    "self.relu = nn.ReLU()\n",
    "```\n",
    "\n",
    "âœ… Effect: Keeps positive values and zeros out negative values, making it easier for the model to learn.\n",
    "\n",
    "### 3ï¸âƒ£ Pooling Layer (nn.MaxPool2d)\n",
    "ðŸ“Œ **What it Does?**\n",
    "* Purpose: Reduces the spatial dimensions of the feature maps, by selecting only the most important features.\n",
    "* Makes the model more robust to minor shifts in the image.\n",
    "* Types of Pooling:\n",
    "  * Max Pooling: Retains the maximum value in a region (best for feature detection).\n",
    "  * Average Pooling: Takes the average value (used less frequently).\n",
    "* In our case, a 2Ã—2 pooling window reduces each 28Ã—28 feature map â†’ 14Ã—14.  \n",
    "ðŸ”¹ **Code in CNN Model**\n",
    "```python\n",
    "self.pool = nn.MaxPool2d(2, 2)\n",
    "```\n",
    "* kernel_size=2 â†’ Takes 2x2 patches.\n",
    "* stride=2 â†’ Moves the window by 2 pixels at a time.\n",
    "* `2,2`: Kernel size & stride, meaning a 2Ã—2 window moves in steps of 2. \n",
    "\n",
    "ðŸ–¼ **Visual Example**\n",
    "* ðŸ”¹ Feature Map (28Ã—28) â†’ After Pooling (14Ã—14)  \n",
    "This reduces computation & overfitting.\n",
    "\n",
    "âœ… Effect: Downsamples the image, making computations faster while retaining important features.\n",
    "\n",
    "\n",
    "### 4ï¸âƒ£ Fully Connected Layers (nn.Linear)\n",
    "ðŸ“Œ **What it Does?**\n",
    "* Purpose: After convolution and pooling, the feature maps are flattened and passed through dense layers for final classification.\n",
    "* Flattens feature maps into a 1D vector and passes it through dense layers for classification.\n",
    "* The CNN now learns to associate patterns with class labels.  \n",
    "ðŸ”¹ **Code in CNN Model**\n",
    "```python\n",
    "self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "self.fc2 = nn.Linear(128, 10)\n",
    "```\n",
    "* Takes flattened features from CNN layers.\n",
    "* Learns complex representations before making predictions.\n",
    "* `32 * 7 * 7`: The flattened feature maps from Conv layers.\n",
    "* `128`: Hidden neurons for feature learning.\n",
    "* `10`: Output neurons (digits 0-9 for classification).\n",
    "\n",
    "âœ… Effect: Converts extracted image features into class predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd101fce",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
